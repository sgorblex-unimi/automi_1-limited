\chapter{Automi \eng{\texorpdfstring{$1$}{1}-limited}}
Come accennato al paragrafo \ref{subs:prel:PDA}, il fatto che gli automi a pila deterministici riconoscano una classe intermedia tra i linguaggi liberi da contesto e quelli regolari ha portato Hibbard a voler definire una generalizzazione del determinismo nei linguaggi liberi da contesto e i loro riconoscitori. Per fare ciò, egli introdusse in \cite{Hibbard:67:CFdet} gli \eng{scan limited automata}, che oggi, con qualche piccola modifica al modello, chiamiamo automi \eng{limited}. Lo studio degli automi limited ha ormai superato il suo scopo iniziale: non riguarda più unicamente il caso deterministico e si presta particolarmente a risultati nell'ambito della complessità descrizionale.

In questo capitolo presentiamo innanzitutto gli automi \eng{$d$-limited} e il loro potere riconoscitivo, poi entriamo nel merito degli automi \eng{$1$-limited}, il nostro oggetto di studio, con una panoramica dei principali risultati che li riguardano.



\section{Automi \eng{d-limited}}
Gli automi \eng{$d$-limited} sono un caso particolare di automi linearmente limitati. Un automa \eng{$d$-limited}, con $d\in\N$, è una macchina di Turing nondeterministica in cui lo spazio di lavoro, che all'inizio contiene l'input, è circoscritto dagli \eng{end-marker} $\lem$ e $\rem$ (come già visto per i 2NFA al paragrafo \ref{subs:prel:NFA}). Inoltre, la capacità di scrittura della macchina è limitata, potendo scrivere su una cella solo durante le prime $d$ visite.
\begin{defin}[automa \eng{$d$-limited}]
	Dato un intero $d\geq 0$, un automa \eng{$d$-limited} ($d$-LA) è una tupla $A=\tuple{Q,\Sigma,\Gamma,\delta,q_0,F}$ dove:
	\begin{itemize}
		\item $Q$ è un insieme finito e non vuoto di stati;
		\item $\Sigma$ è l'alfabeto di input;
		\item $\Gamma\supseteq\Sigma\cup\set{\lem,\rem}$ è l'alfabeto di lavoro (\eng{working alphabet}), dove $\lem$ e $\rem$ circoscrivono l'input nonché lo spazio di lavoro sul nastro. $\Gamma$ è partizionato in $d+1$ sottoinsiemi $\Gamma_0,\Gamma_1,\dots,\Gamma_d$, con $\Gamma_0=\Sigma$ e $\lem,\rem\in\Gamma_d$. L'insieme $\Gamma_k$ rappresenta l'alfabeto a cui appartiene ogni simbolo alla $k$-esima visita della cella che lo contiene. Dopo la $d$-esima visita, la cella rimane invariata (\eng{frozen});
		\item $\delta:Q\times\Gamma\to \subsets{Q\times(\Gamma\setminus\set{\lem,\rem})\times\set{\Left,\Right}}$ è la funzione di transizione. Se a un dato passo l'automa è nello stato $p$, legge il simbolo $\sigma$, e $\delta(p,\sigma)\ni (q,\gamma,D)$, allora:
		      \begin{itemize}
			      \item $q$ è il prossimo stato;
			      \item $\gamma$ è il simbolo che verrà scritto in sostituzione a $\sigma$ nella cella corrente, allo spostamento della testina;
			      \item $D$ e la direzione in cui si muoverà la testina, $\Left$ se a sinistra e $\Right$ se a destra.
		      \end{itemize}
		      La natura del simbolo $\gamma$ è soggetta al partizionamento di $\Gamma$: un simbolo in $\Gamma_k$ viene sostituito con un simbolo in $\Gamma_{k+1}$ (ma un simbolo in $\Gamma_d$ viene sostituito con se stesso). Le visite in cui si cambia direzione contano doppio\footnote{Ciò è una conseguenza del fatto che, in realtà, si contano per ogni cella non le visite, ma le scansioni da sinistra a destra (visite di numero dispari) e quelle da destra a sinistra (visite di numero pari), per cui un cambio di direzione comprende entrambe.}, sostituendo un simbolo in $\Gamma_k$ con un simbolo in $\Gamma_{k+2}$. Le celle contenenti gli \eng{end-marker} non sono mai modificate, né è possibile muoversi a sinistra di $\lem$ e a destra di $\rem$, se non per accettare.
		\item $q_0\in Q$ è lo stato iniziale;
		\item $F\subseteq Q$ è l'insieme degli stati finali.
	\end{itemize}
	Una \emph{configurazione} di un automa $d$-limited si indica con $xqy$, dove $x$ è la parola prima della cella corrente (può essere omessa se $x=\emptyword$), $q$ è lo stato corrente, e $y$ è la parola che inizia con il simbolo nella cella corrente (si omettono $\lem$ e $\rem$). Si scrive $xpy\trans zqw$ se esiste una transizione che porta dalla configurazione $xpy$ a $zqw$ e $xpy\transs zqw$ se esiste una computazione in zero o più passi che porta dalla configurazione $xpy$ a $zqw$.

	Un automa $d$-limited accetta una parola $w\in\Sigma\star$ se e solo se esiste una computazione che, a partire dalla configurazione $q_0w$ (il nastro contenente $\lem w\rem$), termina in uno stato finale $q\in F$ violando il \eng{right end-marker}.

	Un automa $d$-limited si dice deterministico (D$d$-LA) se $\card{\delta(q,\gamma)}\leq 1 ~ \forall q\in Q,\gamma\in\Gamma$. Un automa si dice \eng{limited} se è \eng{$d$-limited} per qualche $d$.
\end{defin}
Sebbene formalmente il simbolo corrente viene sempre sovrascritto, nella pratica ciò non accade. Quando un simbolo deve rimanere invariato, esso viene sostituito con un simbolo equivalente rispetto alla funzione di transizione (si immagini che, ad esempio, $a$ venga sostituito con $a'$ ma comunque rappresentato con $a$). In questo modo si preserva l'informazione originale ma si mantiene la correttezza rispetto al modello. Una tecnica analoga viene usata quando si segna (\eng{mark}) una cella, per esempio sostituendo $a$ con $\bar a$, preservando il simbolo ma dandovi un valore aggiuntivo.

Si noti che gli 0-LA corrispondono esattamente ai 2NFA.

\begin{figure}
	\centering
	\input{img/dla_example.tikz}
	\caption{Rappresentazione di un \la d di esempio in un dato istante.}
\end{figure}



\section{Potenza riconoscitiva}
In \cite{Hibbard:67:CFdet} Hibbard studia il diverso potere riconoscitivo dei D\la d al variare di $d$, con i D\la2 che riconoscono esattamente i linguaggi liberi da contesto deterministici. Nonostante ciò, e nonostante gli \la d siano una restrizione dei LBA, che riconoscono i \eng{context-sensitive}, è noto che i \la d nondeterministici riconoscono esattamente la classe dei linguaggi \eng{context-free}, per qualunque $d\geq2$. Questo risultato deriva dalla costruzione di alcune trasformazioni da modelli equivalenti agli automi a pila ai \la2 e viceversa, combinati con trasformazioni da \la{d+1} a \la d, per $d\geq2$. Una dimostrazione più semplice del potere riconoscitivo dei \la2 si ottiene dal teorema di Chomsky-Schützenberger (\cite{Chomsky:63:algebraCF}) e un \la2 molto semplice che riconosce i linguaggi di Dyck (dettagli in \cite{Pighizzini:19:limited}).

Per quanto riguarda $d<2$, poiché gli \la0 sono esattamente i 2NFA è chiaro che questi riconoscano esattamente i linguaggi regolari. Wagner e Wechsung hanno dimostrato in \cite{Wagner:86:compCompl} che la possibilità di riscrivere una cella durante la sua prima visita non aumenta il potere riconoscitivo, ergo anche gli \la1 riconoscono i linguaggi regolari. Come vedremo, infatti, il vero potere degli \la1 non è nella classe riconosciuta, ma nella complessità della loro descrizione, notevolmente ridotta rispetto ai riconoscitori standard per i linguaggi regolari.

Una panoramica più approfondita dei risultati ottenuti per gli automi $d$-limited, specialmente per $d\geq2$ che qui non trattiamo, si può trovare in \cite{Pighizzini:19:limited}.



\section{Complessità descrizionale}
Non sono necessari particolari costruzioni perché un \la1 simuli un'altra macchina tra i tipici riconoscitori di linguaggi regolari: è sufficiente che ignori la sua capacità di scrivere (2NFA) o quella di muoversi in ambe le direzioni (1NFA), eventualmente aggiungendo uno stato che permetta di muoversi verso destra per accettare violando il right end-marker. È invece non triviale la simulazione opposta, cioè quella di un \la1 da parte di una di tali macchine. Gli estensivi studi di queste simulazioni ci permettono non solo di dimostrare che gli \la1 riconoscano effettivamente i linguaggi regolari, ma anche quale aumento di complessità descrizionale derivi dalla costruzione.


\subsection{Upper bound}
Con una rivisitazione della costruzione di Wagner e Wechsung (teorema 12.1 in \cite{Wagner:86:compCompl}), Pighizzini e Pisoni hanno ottenuto in \cite{Pighizzini:14:limitedRE} l'upper bound del numero di stati necessari a un automa a stati finiti per simulare un automa 1-limited. La simulazione si basa sul concetto di tabella di transizione, già usato nella conversione da 2DFA in 1DFA presentata in \cite{Shepherdson:59:reduction2to1way}. Dato un \la1 di $n$ stati, la costruzione produce un 1NFA di un numero di stati esponenziale in $n$, oppure un 1DFA doppiamente esponenziale, indipendentemente dalla dimensione dell'alfabeto di lavoro. Se il \la1 è deterministico, inoltre, la stessa costruzione produce un 1DFA di numero di stati semplicemente esponenziale.
\begin{theor}[Teorema 2 in \cite{Pighizzini:14:limitedRE}]\label{thm:a1l:upper}
	Sia $M$ un \la1 di $n$ stati.
	\begin{enumerate}[(a)]
		\item \label{itm:a1l:up:NFA} $M$ può essere simulato da un 1NFA con $n\cdot2^{n^2}$ stati;
		\item \label{itm:a1l:up:DFA} $M$ può essere simulato da un 1DFA con $2^{n\cdot2^{n^2}}$ stati;
		\item \label{itm:a1l:up:det} se $M$ è deterministico, può essere simulato da un 1DFA con al più $n\cdot (n+1)^n$ stati.
	\end{enumerate}
\end{theor}
\begin{proof}
	Sia $M=\tuple{Q,\Sigma,\Gamma,\delta,q_0,F}$ un \la1, con $\card{Q}=n$.

	\ref{itm:a1l:up:NFA} Per costruire un 1NFA $A$ che simuli $M$ ci occorre uno strumento che trasferisca nella memoria a stati finiti le due facoltà degli 1-LA che $A$ non possiede: la scrittura alla prima visita e il movimento della testina verso sinistra. Ogni transizione di $A$ legge un simbolo nuovo, perciò dovrà simulare una o più transizioni di $M$.
	Dal momento che $M$ accetta violando l'end-marker destro, ogni cella deve essere visitata, e la prima visita di ogni cella segue l'ordine delle celle stesse, da sinistra verso destra. Tra la prima visita di una cella $\sigma_k$ e quella della successiva $\sigma_{k+1}$, l'unica computazione possibile è una computazione two-way in sola lettura, poiché tutte le celle che precedono $\sigma_{k+1}$ sono ormai immutabili. Una tabella di transizione rappresenta questa computazione come una relazione tra gli stati in cui può iniziare e quelli in cui può finire. Formalmente, data una stringa $z\in\Gamma_1^+$ una tabella di transizione è una relazione binaria $\tau_z\subseteq Q\times Q$ tale che
	\begin{equation*}
		(p,q)\in\tau_z \iff z'pYw \transs zqw = z'Yqw
	\end{equation*}
	con $Y\in\Gamma_1,p,q\in Q,z=z'Y,w\in\Gamma\star$. Se la testina punta a $Y$ ed è preceduta da $z'$, la tabella di transizione di $z$ indica quindi, per ogni stato in cui $M$ può trovarsi, i possibili stati in cui può uscire dalla porzione di nastro contenente $z'Y$ per visitare la cella alla destra di $Y$. La figura \ref{fig:a1l:ttt} dà una rappresentazione di $\tau_z$. Una tabella di transizione dipende ovviamente dalla stringa su cui è costruita, ma non è, in generale, unica di tale stringa (infatti le possibili tabelle sono finite).

	\begin{figure}
		\centering
		\subfloat[][$(p,q)\in \tau_{z}$ oppure $(p,q)\in t_Y(\tau_{z'})$\label{fig:a1l:ttt}]
		{
			\input{img/transtablet.tikz}
		} \qquad
		\subfloat[][$(p,q)\in m_X(\tau_z)$\label{fig:a1l:ttm}]{
			\input{img/transtablem.tikz}}
		\caption{Rappresentazione delle computazioni che determinano l'appartenenza della coppia di stati $(p,q)$ a diverse tabelle di transizione. $z=z'Y$.}
	\end{figure}

	Fissato $X\in\Gamma_1$, introduciamo ora due funzioni $t_X,m_X:\subsets{Q\times Q}\to\subsets{Q\times Q}$ che trasformano tabelle di transizione. Intuitivamente, $t_X$ trasforma una tabella $\tau_z$ in $\tau_{zX}$, mentre $m_X(\tau_z)$ produce una tabella leggermente diversa, che descrive la computazione dall'ultimo simbolo di $z$ al simbolo dopo $zX$:
	\begin{equation*}
		(p,q)\in m_X(\tau_z) \iff z'pYXw \transs zXqw = z'YXqw
	\end{equation*}
	Le funzioni $t$ e $m$ sono rappresentate rispettivamente nelle figure \ref{fig:a1l:ttt} e \ref{fig:a1l:ttm}.

	Queste definizioni sono ben poste dal momento che è sufficiente conoscere $\tau_z$, senza necessariamente conoscere $z$, per produrre $m_X(\tau_z)$ e $t_X(\tau_z)$. Ciò è possibile perché, muovendosi a sinistra di $X$, si può consultare $\tau_z$ per ottenere lo stato in cui si torna in $X$, mentre in $X$ è sufficiente calcolare $\delta$. In altre parole, se $\tau_z=\tau_w$ allora $t_X(\tau_z)=t_X(\tau_w)$ e $m_X(\tau_z)=t_X(\tau_w)$. Definizioni più formali sono presenti in \cite{Pighizzini:14:limitedRE}.

	Siamo ora pronti a descrivere la forma e il comportamento di $A$.
	Ogni stato di $A$ corrisponde in $M$ alla prima visita di una cella, e una transizione deve simulare una computazione di $M$ che termina con la prima visita della successiva. Precisamente, ogni stato di $A$ è una coppia $[q,\tau]$:
	\begin{itemize}
		\item la prima componente è lo stato in cui si trova la macchina simulata $M$ durante la prima visita del simbolo corrente;
		\item la seconda componente è una tabella di transizione che permette, qualora la macchina simulata si muova a sinistra, di sapere in che stati può tornare nella posizione attuale.
	\end{itemize}
	Si ipotizzi ora che $M$ sia nella configurazione $zraw$, durante la prima visita della cella contenente $a$ ($z\in\Gamma_1\star,r\in Q,a\in\Sigma,w\in\Sigma\star$). Simulando $M$, $A$ avrà uno stato corrente $[r,\tau]$, dove $\tau=\tau_z$ (ma $A$ non ha traccia di $z$). Poiché questa è la prima visita di $a$, la prossima transizione di $M$ sostituirà il simbolo con un altro, diciamo $X$. Separiamo ora i casi di movimento della testina a destra e a sinistra.
	\begin{itemize}
		\item se la testina si muove a destra in uno stato $s$ (fig. \ref{fig:a1l:mright}), ci troviamo in corrispondenza della prima visita della cella successiva, perciò $A$ può spostarsi direttamente in un nuovo stato. La prima componente del nuovo stato sarà ovviamente $s$, mentre la tabella va aggiornata in modo da contenere l'informazione sulla cella appena lasciata, che è stata anche riscritta. La tabella per il nuovo stato sarà dunque $t_X(\tau)$, che rappresenta le possibili computazioni da $X$ per uscire dalla porzione di nastro che vi termina qualora $M$ ci dovesse tornare. Estendendo il caso al nondeterminismo il movimento a destra può variare nello stato $s$ e nel simbolo scritto $X$, sono quindi necessarie le corrispondenti transizioni in ogni stato $[s,t_X(\tau)]$;
		\item se la testina si muove verso sinistra in uno stato $s$ (fig. \ref{fig:a1l:mleft}), occorre "aspettare" che $M$ effettui una computazione che termini a destra di $X$, nella prima visita di una nuova cella. La tabella dello stato risultante, come nel caso precedente, sarà $t_X(\tau)$, poiché la computazione a sinistra della nuova cella non può essere influenzata da ulteriori scritture. Lo stato risultante $q$ ci viene invece dato da $(s,q)\in m_X(\tau)$, che descrive il comportamento di $M$ all'arrivo nella nuova cella a partire dallo stato $s$ e dal simbolo a sinistra di $X$. Considerando anche il nondeterminismo, per ogni stato $s$ e simbolo $X$ vanno quindi costruite transizioni in $[q,t_X(\tau)]$, per ogni stato $q$ tale che $(s,q)\in m_X(\tau)$.
	\end{itemize}

	\begin{figure}
		\centering
		\subfloat[][$M$ muove la testina a destra. $A$ passa nello stato ${[s,t_X(\tau)]}$.\label{fig:a1l:mright}]{
			\hspace{.7cm}\input{img/mright.tikz}\hspace{.7cm}}
		\qquad
		\subfloat[][$M$ muove la testina a sinistra. $A$ passa nello stato ${[q,t_X(\tau)]}$.\label{fig:a1l:mleft}]{
			\hspace{.3cm}\input{img/mleft.tikz}\hspace{.3cm}}
		\caption{I due tipi di computazione di $M$ che corrispondono a una transizione in $A$.}
	\end{figure}

	Lo stato iniziale è la coppia $[q_0,\tau_\lem]$. Poiché un 1NFA non può leggere il simbolo $\rem$, è necessario un altro meccanismo per rendere uno stato finale. Uno stato $[s,\tau]$ è finale se e solo se $M$, giunto a $\rem$ nello stato $s$, possiede una computazione (in sola lettura e su tutto il nastro) che termina in uno stato finale $f\in F$ superato l'end-marker, cioè se $(s,f)\in t_\rem(\tau)$.

	Formalmente, $A:=\tuple{Q',\Sigma,\delta',q_0',F'}$ con
	\begin{itemize}
		\item $Q':=Q\times\subsets{Q\times Q}$;
		\item $q_0':=[q_0,\tau_\lem]$;
		\item $F':=\set{[p,\tau]\mid \exists q\in F: (p,q)\in t_\rem(\tau)}$
		\item dati $r,s\in Q,a\in\Sigma,X\in\Gamma_1,\tau\in\subsets{Q\times Q}$ le seguenti transizioni:
		      \begin{itemize}
			      \item per ogni $(s,X,\Right)\in\delta(r,a)$, $\delta'([r,\tau],a)$ contiene $[s,t_X(\tau)]$;
			      \item per ogni $(s,X,\Left)\in\delta(r,a)$, $\delta'([r,\tau],a)$ contiene $[q,t_X(\tau)]$ per ogni $q\in Q$ tale che $(s,q)\in m_X(\tau)$.
		      \end{itemize}
	\end{itemize}
	L'1NFA risultante ha $n\times 2^{n^2}$ stati. Benché $t_X$ e $m_X$ restituiscano diverse tabelle al variare di $X$, il numero di tabelle possibili, e quindi di stati di $A$, non dipende da $\card{\Gamma}$.

	\ref{itm:a1l:up:DFA} usando la subset construction (\cite{Rabin:59:NFA}), $A$ può essere convertito in un 1DFA con $2^{2^{n^2}}$ stati.

	\ref{itm:a1l:up:det} se $M$ è deterministico, ogni tabella di transizione è una funzione parziale $Q\to Q$, perciò $A$ ha al più $n\cdot(n+1)^n$ stati ($n+1$ immagini poiché si include la possibilità di non uscire dal segmento di nastro). Inoltre, per ogni tabella $\tau$, ogni stato $[r,\tau]$ possiede esattamente una transizione derivante da una transizione di $M$ per ciascun simbolo di input. $A$ è quindi un 1DFA.
\end{proof}


\subsection{Lower bound}
Studieremo ora i lower bound di conversione, facendo uso di \eng{witness languages} per dimostrare che esistono determinati casi in cui le complessità di conversione ottenute negli upper bound non possono essere significativamente migliorate. Per fare ciò, si cerca una famiglia di linguaggi per il cui riconoscimento esiste un \la1 con certo numero di stati $n$ e, al contempo, per cui un 1DFA necessita di un numero doppiamente esponenziale in $n$ di stati e un 1NFA, oppure 2NFA, 2DFA o D\la1 un numero esponenziale\footnote{Non è necessario, in generale, che sia la stessa famiglia di linguaggi a dimostrare l'ottimalità delle diverse conversioni; tuttavia presenteremo un caso in cui ciò si verifica.}.
\begin{theor}
	Esistono infiniti \la1 di $n$ stati la cui conversione in 1DFA richiede un numero doppiamente esponenziale in $n$ di stati.
\end{theor}

Si consideri il linguaggio $L_n$, dove $1\leq n\in\N$ è un parametro, delle parole binarie a blocchi di $n$ simboli in cui $n$ blocchi sono uguali:
\begin{align*}
	L_n := \{ & x_1x_2\cdots x_k\mid k\geq0, x_1,x_2,\dots,x_k\in\{0,1\}^n,                                   \\
	          & \exists i_1,i_2,\dots,i_n\in\{1,\dots,k\},i_1<i_2<\dots<i_n, x_{i_1}=x_{i_2}=\dots=x_{i_n}\}
\end{align*}

\begin{theor}
	$L_n$ può essere riconosciuto da un \la1 con un numero di stati di $O(n)$ e un alfabeto di lavoro indipendente da $n$.
\end{theor}
\begin{proof}
	Un \la1 $A_n$ può riconoscere $L_n$ come segue:
	\begin{enumerate}
		\SetKwData{B}{b}\SetKwData{C}{c}
		\item $A_n$ effettua una scansione preliminare dell'input, da sinistra verso destra, che verifichi tramite un contatore modulo $n$ che la parola sia effettivamente composta da blocchi di $n$ simboli, ossia che la sua lunghezza sia multipla di $n$. Se si raggiunge il right end-marker con il contatore non a zero, la macchina si ferma rifiutando. Durante questa scansione, l'unica in cui $A_n$ ha facoltà di scrittura, la macchina sceglie inoltre in modo nondeterministico delle celle, provando a indovinare quelle che danno inizio ai blocchi uguali. Ciò viene fatto sostituendo i simboli con una loro versione segnata, che però mantenga l'informazione originale (per esempio $0$ in $\hat 0$), e in corrispondenza dell'azzeramento del contatore, in modo che i simboli segnati siano necessariamente all'inizio di blocchi. Questa fase richiede $O(n)$ stati per il contatore;
		\item viene poi effettuata una scansione verso sinistra che verifichi che il numero di celle segnate, e quindi di blocchi candidati, sia $n$. Anche questa scansione richiede $O(n)$ stati;
		\item \label{itm:a1l:lowLn:LA3} la macchina prosegue poi verificando in sola lettura l'uguaglianza dei blocchi candidati, confrontando coppie di blocchi simbolo a simbolo. Per fare ciò la macchina implementa l'algoritmo \ref{alg:a1l:lowLn:3f}, una versione rivista e corretta dell'algoritmo presentato in \cite{Pighizzini:14:limitedRE}, che presentava qualche errore. Si ipotizzi di prendere in considerazione una coppia di blocchi candidati successivi. L'algoritmo fa uso di due variabili: la variabile intera \C, il cui dominio è $\set{0,\dots,n-1}$, rappresenta l'indice del simbolo che dev'essere confrontato nei due blocchi; la variabile \B contiene una copia del simbolo all'indice \C del primo blocco per confrontarla con il corrispondente simbolo nel secondo. Inizialmente $A_n$ scansiona da $\lem$ verso destra alla ricerca del primo simbolo segnato, e \C è inizializzata a $0$. A questo punto si entra nel ciclo principale, che confronta due blocchi adiacenti tra quelli segnati. La porzione di codice a righe \refalgrange{algln:a1l:lowLn:3f}{1}{2} sposta la testina alla posizione di indice \C del primo blocco decrementando \C, salva una copia del simbolo in \B, quindi ripristina il valore di \C (modificando direttamente \C si risparmia l'utilizzo di un ulteriore indice variabile). Quindi la macchina prosegue individuando l'inizio del secondo blocco, accettando se trova invece $\rem$. Effettua quindi una procedura simile alla precedente per localizzare il simbolo in posizione \C (righe \refalgrange{algln:a1l:lowLn:3f}{3}{4}), questa volta però confrontandolo con quello contenuto in \B. Se i due sono diversi la macchina rifiuta, altrimenti prosegue. A questo punto, se $\C=n-1$ significa che i due blocchi sono stati confrontati, quindi si passa al confronto del secondo con il prossimo dei candidati. Per fare ciò è necessario unicamente resettare \C a $0$, dal momento che la testina è già nella corretta posizione. Se invece $\C<n-1$, si incrementa \C e si torna all'inizio del primo blocco per confrontare il prossimo simbolo. Questa fase richiede un numero di stati di $O(n)$ per memorizzare i valori di \B e \C.
	\end{enumerate}

	\IncMargin{1em}
	\begin{algorithm}
		\input{img/alg_Ln.tex}
		\caption{\hyperref[itm:a1l:lowLn:LA3]{Terza fase} del riconoscimento di $L_n$ da parte di $A_n$}
		\label{alg:a1l:lowLn:3f}
	\end{algorithm}
	\DecMargin{1em}
\end{proof}

Per dimostrare l'ottimalità dell'upper bound trovato in precedenza, dimostriamo che qualunque conversione non porterebbe alla costruzione di un 1DFA equivalente ad $A_n$ che abbia meno di un numero doppiamente esponenziale in $n$ di stati, poiché un tale 1DFA non può esistere. Il risultato viene poi esteso per l'ottimalità dei bound relativi a 1NFA, 2NFA, 2DFA e D\la1.
\begin{theor}\label{thm:a1l:lowLn}
	Sia $1\leq n\in\N$. Allora:
	\begin{enumerate}[(a)]
		\item \label{itm:a1l:lowLn:DFA} un 1DFA che riconosca $L_n$ necessita di un numero di stati doppiamente esponenziale in $n$;
		\item \label{itm:a1l:lowLn:1LA} un \la1 che riconosca $L_n$ necessita di un numero di stati almeno polinomiale in $n$;
		\item \label{itm:a1l:lowLn:NFA} un D\la1, un 2NFA, 2DFA o 1NFA che riconosca $L_n$ necessita di un numero di stati esponenziale in $n$.
	\end{enumerate}
\end{theor}
\begin{proof}
	\ref{itm:a1l:lowLn:DFA} Per dimostrare che un 1DFA che riconosca $L_n$ necessita di $2^{2^n}$ stati usiamo la tecnica delle stringhe distinguibili. Fissato un alfabeto, due stringhe $x$ e $y$ si dicono \emph{distinguibili} rispetto a un linguaggio $L$ se e solo se esiste una stringa $z$ tale che esattamente una tra le parole $xz$ e $yz$ appartiene a $L$. La cardinalità di un qualunque insieme di stringhe a due a due distinguibili è lower bound per il numero di stati necessari a un 1DFA per riconoscere il relativo linguaggio\footnote{Questa proprietà è una conseguenza del teorema di Myhill-Nerode se si sceglie come relazione di equivalenza l'indistinguibilità di stringhe.}.

	Sia $x_1,x_2,\dots,x_{2^n}$, una lista in qualunque ordine di tutti i possibili blocchi, cioè stringhe in $\set{a,b}^n$. Sia $F:=\set{f: \set{0,\dots,2^n}\to\set{0,\dots,n-1}}$ l'insieme delle funzioni che mappano gli indici dei blocchi a interi tra $0$ e $n-1$. Scelto $f\in F$, sia $w_f$ la parola formata dalla giustapposizione dei blocchi $x_1,x_2,\dots,x_{2^n}$, il blocco di indice $i$ ripetuto $f(i)$ volte, ossia $w_f:=x_1^{f(1)}x_2^{f(2)}\cdots x_{2^n}^{f(2^n)}$. Si considerino ora due funzioni $f,g\in F$ tali che per un certo indice $j$, $f(j)\neq g(j)$. Le stringhe $w_f$ e $w_g$ sono distinguibili dalla stringa $z:=x_j^{n-\max(f(j),g(j))}$, poiché una e una sola delle due parole $w_fz$ e $w_gz$ raggiunge $n$ ripetizioni del blocco $x_j$. Per esempio, se $f(j)>g(j)$:
	\begin{equation*}
		w_fz=x_1\cdots \underbrace{x_j\cdots x_j}_{f(j)} \cdots x_{2^n}\underbrace{x_j\cdots x_j}_{n-f(j)}\in L_n \qquad w_gz=x_1\cdots \underbrace{x_j\cdots x_j}_{g(j)} \cdots x_{2^n}\underbrace{x_j\cdots x_j}_{n-f(j)}\notin L_n
	\end{equation*}
	Dove il totale di ripetizioni del blocco $x_j$ sono $n$ per $w_fz$ e $g(j)+n-f(j)<n$ per $w_gz$.

	Ne si deduce, quindi, che la cardinalità dell'insieme delle parole $w_f$ è lower bound per il numero di stati di una 1DFA che riconosca $L_n$. Tale numero coincide con il numero di possibili funzioni $f$, ossia con $|F|=n^{2^n}=\Omega(2^{2^n})$.

	\ref{itm:a1l:lowLn:1LA} Se il numero di stati di un \la1 che riconosca $L_n$ fosse meno che polinomiale in $n$, allora in virtù del teorema \ref{thm:a1l:upper} si potrebbe costruire un 1DFA meno che doppiamente esponenziale in $n$, il che contraddirebbe \ref{itm:a1l:lowLn:DFA}.

	\ref{itm:a1l:lowLn:NFA} Con un ragionamento analogo, considerando le costruzioni che permettono ai 1DFA di simulare 1NFA, 2NFA, 2DFA e D\la1, tutte di crescita almeno esponenziale, dimostriamo che è impossibile che una di queste macchine che riconosca $L_n$ abbia un numero di stati meno che esponenziale in $n$.
\end{proof}
\noindent La dimostrazione di Pighizzini e Pisoni (\cite{Pighizzini:14:limitedRE}) estende il lower bound per i 1DFA a $((2^n-2)\cdot(\frac{n-1}{n})^2+1)\cdot n^{2^n}+1$ (tramite distinguibilità) e quello dei 1NFA a $n^2\cdot2^n$ (tramite \eng{fooling set}).

Il teorema \ref{thm:a1l:lowLn}, oltre a dimostrare che le conversioni da \la1 non possono essere migliorate significativamente (ossia così da rimuovere un livello di esponenzialità), trova un lower bound esponenziale alla conversione da \la1 a D\la1:
\begin{corol}
	La simulazione di \la1 nondeterministici da parte di \la1 deterministici richiede un fattore esponenziale di stati.
\end{corol}
\begin{proof}
	L'esistenza di un D\la1 deterministico meno che esponenziale in $n$ che riconosca $L_n$ permetterebbe la costruzione di un 1DFA equivalente meno che doppiamente esponenziale in $n$ con la simulazione di cui al teorema \ref{thm:a1l:upper}, il che alla luce del teorema \ref{thm:a1l:lowLn} è assurdo.
\end{proof}
