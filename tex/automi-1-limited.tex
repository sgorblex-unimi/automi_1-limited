\chapter{Automi \texorpdfstring{$1$}{1}-limited}\label{cha:a1l}
Come accennato nel paragrafo \ref{subs:prel:PDA}, il fatto che gli automi a pila deterministici riconoscano una classe intermedia tra i linguaggi liberi dal contesto e quelli regolari ha portato Hibbard a voler definire una generalizzazione del determinismo nei linguaggi liberi dal contesto e i loro riconoscitori. Per fare ciò, egli introdusse in \cite{Hibbard:67:CFdet} gli \eng{scan-limited automata}, oggi chiamati automi \eng{limited}. Lo studio degli automi limited ha ormai superato il suo scopo iniziale: non riguarda più unicamente il caso deterministico ed è particolarmente incentrato sulla complessità descrizionale, poiché tali macchine forniscono una descrizione molto più succinta rispetto ai riconoscitori classici equivalenti.

In questo capitolo presentiamo innanzitutto gli automi \eng{$d$-limited} e la loro potenza riconoscitiva, poi entriamo nel merito degli automi \eng{$1$-limited}, il nostro oggetto di studio, con una panoramica dei principali risultati che li riguardano.



\section{Automi \eng{d-limited}}
Gli automi \eng{$d$-limited} sono un caso particolare di automi linearmente limitati. Un automa \eng{$d$-limited}, con $d\in\N$, è una macchina di Turing nondeterministica in cui lo spazio di lavoro, che all'inizio contiene l'input, è circoscritto dagli end-marker $\lem$ e $\rem$ (come già visto per i 2NFA al paragrafo \ref{subs:prel:NFA}). Inoltre, la capacità di scrittura della macchina è limitata, potendo scrivere su una cella solo durante le prime $d$ visite.
\begin{defin}[automa $d$-limited]
	Dato un intero $d\geq 0$, un \emph{automa $d$-limited} ($d$-LA) è una tupla $A=\tuple{Q,\Sigma,\Gamma,\delta,q_0,F}$ dove:
	\begin{itemize}
		\item $Q$ è un insieme finito e non vuoto di stati;
		\item $\Sigma$ è l'alfabeto di input;
		\item $\Gamma\supseteq\Sigma\cup\set{\lem,\rem}$ è l'alfabeto di lavoro (\eng{work alphabet}), dove $\lem$ e $\rem$ circoscrivono l'input nonché lo spazio di lavoro sul nastro. $\Gamma$ è partizionato in $d+1$ sottoinsiemi $\Gamma_0,\Gamma_1,\dots,\Gamma_d$, con $\Gamma_0=\Sigma$ e $\lem,\rem\in\Gamma_d$. L'insieme $\Gamma_k$ rappresenta l'insieme di simboli che una cella può contenere alla sua $k$-esima visita. Dopo la $d$-esima visita, la cella rimane invariata;
		\item $\delta:Q\times\Gamma\to \subsets{Q\times(\Gamma\setminus\set{\lem,\rem})\times\set{\Left,\Right}}$ è la funzione di transizione. Se a un dato passo l'automa è nello stato $p$, legge il simbolo $\sigma$, e $\delta(p,\sigma)\ni (q,\gamma,D)$, allora $A$:
		      \begin{itemize}
			      \item si sposta nello stato $q$;
			      \item sostituisce il simbolo $\sigma$ con $\gamma$ nella cella corrente;
			      \item sposta la testina in una cella adiacente a quella corrente: verso sinistra se $D=\Left$ e verso destra se $D=\Right$.
		      \end{itemize}
		      La natura del simbolo $\gamma$ è soggetta al partizionamento di $\Gamma$: un simbolo in $\Gamma_k$ viene sostituito con un simbolo in $\Gamma_{k+1}$ (ma un simbolo in $\Gamma_d$ viene sostituito con se stesso). Le visite in cui si cambia direzione contano doppio,\footnote{Ciò è una conseguenza del fatto che, in realtà, si contano per ogni cella non le visite, ma le scansioni da sinistra a destra (visite di numero dispari) e quelle da destra a sinistra (visite di numero pari), per cui un cambio di direzione comprende entrambe.} sostituendo un simbolo in $\Gamma_k$ con un simbolo in $\Gamma_{k+2}$. Le celle contenenti gli end-marker non sono mai modificate, né è possibile muoversi a sinistra di $\lem$ e a destra di $\rem$, se non per accettare.
		\item $q_0\in Q$ è lo stato iniziale;
		\item $F\subseteq Q$ è l'insieme degli stati finali.
	\end{itemize}
	Una \emph{configurazione} di un automa $d$-limited si indica con $xqy$, dove $x$ è la parola prima della cella corrente (può essere omessa se $x=\emptyword$), $q$ è lo stato corrente, e $y$ è la parola che inizia con il simbolo nella cella corrente (si omettono $\lem$ e $\rem$). Si scrive $xpy\trans zqw$ se esiste una transizione che porta dalla configurazione $xpy$ a $zqw$ e $xpy\transs zqw$ se esiste una computazione in zero o più passi che porta dalla configurazione $xpy$ a $zqw$.

	Un automa $d$-limited accetta una parola $w\in\Sigma\star$ se e solo se esiste una computazione che, a partire dalla configurazione $q_0w$ (il nastro contenente $\lem w\rem$), termina in uno stato finale $q\in F$ violando il right end-marker.

	Un automa $d$-limited si dice deterministico (D$d$-LA) se $\card{\delta(q,\gamma)}\leq 1 ~ \forall q\in Q,\gamma\in\Gamma$. Un automa si dice \eng{limited} se è \eng{$d$-limited} per qualche $d$.
\end{defin}

\begin{figure}
	\centering
	\input{img/dla_example.tikz}
	\caption{Rappresentazione di un \la d di esempio in un dato istante.}
\end{figure}



\section{Potenza riconoscitiva}
In \cite{Hibbard:67:CFdet} Hibbard studia la potenza riconoscitiva dei D\la d al variare di $d$, con i D\la2 che riconoscono esattamente i linguaggi liberi dal contesto deterministici. Nonostante ciò, e nonostante gli \la d siano una restrizione dei LBA, che riconoscono i context-sensitive, è noto che i \la d nondeterministici riconoscono esattamente la classe dei linguaggi context-free, per qualunque $d\geq2$. Questo risultato deriva dalla costruzione di alcune trasformazioni da modelli equivalenti agli automi a pila ai \la2 e viceversa, combinati con trasformazioni da \la{(d+1)} a \la d, per $d\geq2$. Una dimostrazione più semplice della potenza riconoscitiva dei \la2 si ottiene dall'applicazione del teorema di Chomsky-Schützenberger (\cite{Chomsky:63:algebraCF}) in una costruzione con un \la2 che riconosce i linguaggi di Dyck (dettagli in \cite{Pighizzini:19:limited}).

Per quanto riguarda $d<2$, poiché gli \la0 sono esattamente i 2NFA è chiaro che questi riconoscano esattamente i linguaggi regolari. Wagner e Wechsung hanno dimostrato in \cite{Wagner:86:compCompl} che la possibilità di riscrivere una cella durante la sua prima visita non aumenta la potenza riconoscitiva, ergo anche gli \la1 riconoscono i linguaggi regolari. Come vedremo, infatti, il valore di studio degli \la1 non è nella classe riconosciuta, ma nella complessità della loro descrizione, notevolmente ridotta rispetto ai riconoscitori standard per i linguaggi regolari.

Una panoramica più approfondita dei risultati ottenuti per gli automi $d$-limited, specialmente per $d\geq2$ che qui non trattiamo, si può trovare in \cite{Pighizzini:19:limited}.



\section{Complessità descrizionale}
Limitatamente alla complessità descrizionale, gli automi $1$-limited vengono valutati in termini del loro numero di stati e della cardinalità del loro alfabeto di lavoro. Infatti, la loro descrizione sarà limitata da un polinomio di questi due fattori.

Non sono necessari particolari costruzioni perché un \la1 simuli un'altra macchina tra i tipici riconoscitori di linguaggi regolari: è sufficiente che ignori la sua capacità di scrivere (2NFA) o quella di muoversi in ambe le direzioni (1NFA). È invece non triviale la simulazione opposta, cioè quella di un \la1 da parte di una di tali macchine. Gli estensivi studi di queste simulazioni ci permettono non solo di dimostrare che gli \la1 caratterizzano i linguaggi regolari, ma anche quale aumento di complessità descrizionale derivi dalla costruzione.


\subsection{Upper bound}\label{subs:a1l:up}
Con una rivisitazione della costruzione di Wagner e Wechsung (teorema 12.1 in \cite{Wagner:86:compCompl}), Pighizzini e Pisoni hanno ottenuto in \cite{Pighizzini:14:limitedRE} l'upper bound del numero di stati sufficienti a un automa a stati finiti per simulare un automa $1$-limited. La simulazione si basa sul concetto di tabella di transizione, già usato nella conversione da 2DFA in 1DFA presentata in \cite{Shepherdson:59:reduction2to1way}. Dato un \la1 di $n$ stati, la costruzione produce un 1NFA di un numero di stati esponenziale in $n$, oppure un 1DFA doppiamente esponenziale, indipendentemente dalla dimensione dell'alfabeto di lavoro. Se il \la1 è deterministico, inoltre, la stessa costruzione produce un 1DFA di numero di stati semplicemente esponenziale.
\begin{theor}[Teorema 2 in \cite{Pighizzini:14:limitedRE}]\label{thm:a1l:upper}
	Sia $M$ un \la1 di $n$ stati.
	\begin{enumerate}[(a)]
		\item \label{itm:a1l:up:NFA} $M$ può essere simulato da un 1NFA con $n\cdot2^{n^2}$ stati;
		\item \label{itm:a1l:up:DFA} $M$ può essere simulato da un 1DFA con $2^{n\cdot2^{n^2}}$ stati;
		\item \label{itm:a1l:up:det} se $M$ è deterministico, può essere simulato da un 1DFA con al più $n\cdot (n+1)^n$ stati.
	\end{enumerate}
\end{theor}
\begin{proof}
	Sia $M=\tuple{Q,\Sigma,\Gamma,\delta,q_0,F}$ un \la1, con $\card{Q}=n$.

	\ref{itm:a1l:up:NFA} Per costruire un 1NFA $A$ che simuli $M$, occorre uno strumento che trasferisca nella memoria a stati finiti le due facoltà degli 1-LA che $A$ non possiede: la scrittura alla prima visita e il movimento della testina verso sinistra. Ogni transizione di $A$ legge un simbolo nuovo, perciò dovrà simulare una o più transizioni di $M$.
	Dal momento che $M$ accetta violando l'end-marker destro, ogni cella deve essere visitata, e la prima visita di ogni cella segue l'ordine delle celle stesse, da sinistra verso destra. Tra la prima visita di una cella $\sigma_k$ e quella della successiva $\sigma_{k+1}$, l'unica computazione possibile è una computazione two-way in sola lettura, poiché tutte le celle che precedono $\sigma_{k+1}$ sono ormai immutabili. Una tabella di transizione rappresenta questa computazione come una relazione tra gli stati in cui può iniziare e quelli in cui può finire. Formalmente, data una stringa $z\in\Gamma_1^+$, una tabella di transizione è una relazione binaria $\tau_z\subseteq Q\times Q$ tale che
	\begin{equation*}
		(p,q)\in\tau_z \iff z'pYw \transs zqw = z'Yqw
	\end{equation*}
	con $Y\in\Gamma_1,p,q\in Q,z=z'Y,w\in\Gamma\star$. Se il simbolo nella cella corrente è $Y$ e lo precede la stringa $z'$, la tabella di transizione di $z$ indica quindi, per ogni stato in cui $M$ può trovarsi, i possibili stati in cui può uscire dalla porzione di nastro contenente $z'Y$ per visitare la cella alla destra di $Y$. La figura \ref{fig:a1l:ttt} dà una rappresentazione di $\tau_z$. Una tabella di transizione dipende ovviamente dalla stringa su cui è costruita, ma non è, in generale, unica di tale stringa (infatti le possibili tabelle sono finite).

	\begin{figure}
		\centering
		\subfloat[][$(p,q)\in \tau_{z}$ oppure $(p,q)\in t_Y(\tau_{z'})$\label{fig:a1l:ttt}]
		{
			\input{img/transtablet.tikz}
		} \qquad
		\subfloat[][$(p,q)\in m_X(\tau_z)$\label{fig:a1l:ttm}]{
			\input{img/transtablem.tikz}}
		\caption{Rappresentazione delle computazioni che determinano l'appartenenza della coppia di stati $(p,q)$ a diverse tabelle di transizione. $z=z'Y$.}
	\end{figure}

	Fissato $X\in\Gamma_1$, introduciamo ora due funzioni $t_X,m_X:\subsets{Q\times Q}\to\subsets{Q\times Q}$ che trasformano tabelle di transizione. Intuitivamente, $t_X$ trasforma una tabella $\tau_z$ in $\tau_{zX}$, mentre $m_X(\tau_z)$ produce una tabella leggermente diversa, che descrive la computazione dall'ultimo simbolo di $z$ al simbolo dopo $zX$:
	\begin{equation*}
		(p,q)\in m_X(\tau_z) \iff z'pYXw \transs zXqw = z'YXqw\text.
	\end{equation*}
	Le funzioni $t$ e $m$ sono rappresentate rispettivamente nelle figure \ref{fig:a1l:ttt} e \ref{fig:a1l:ttm}.

	Queste definizioni sono ben poste dal momento che è sufficiente conoscere $\tau_z$, senza necessariamente conoscere $z$, per produrre $m_X(\tau_z)$ e $t_X(\tau_z)$. Ciò è possibile perché, muovendosi a sinistra di $X$, si può consultare $\tau_z$ per ottenere lo stato in cui si torna a leggere $X$, mentre nel momento in cui la testina è su $X$ è sufficiente calcolare $\delta$. In altre parole, se $\tau_z=\tau_w$ allora $t_X(\tau_z)=t_X(\tau_w)$ e $m_X(\tau_z)=t_X(\tau_w)$. Per maggiori dettagli si veda \cite{Pighizzini:14:limitedRE}.

	Siamo ora pronti a descrivere la forma e il comportamento di $A$.
	Ogni stato di $A$ corrisponde in $M$ alla prima visita di una cella, e una transizione deve simulare una computazione di $M$ che termina con la prima visita della successiva. Precisamente, ogni stato di $A$ è una coppia $[q,\tau]$:
	\begin{itemize}
		\item la prima componente è lo stato in cui si trova la macchina simulata $M$ durante la prima visita del simbolo corrente;
		\item la seconda componente è una tabella di transizione che permette, qualora la macchina simulata si muova a sinistra, di sapere in che stati può tornare nella posizione attuale.
	\end{itemize}
	Si ipotizzi ora che $M$ sia nella configurazione $zraw$, con $z\in\Gamma_1\star,r\in Q,a\in\Sigma,w\in\Sigma\star$, durante la prima visita della cella contenente $a$. Simulando $M$, $A$ avrà uno stato corrente $[r,\tau]$, dove $\tau=\tau_z$ (ma $A$ non ha traccia di $z$). Poiché questa è la prima visita di $a$, la prossima transizione di $M$ sostituirà il simbolo con un altro, diciamo $X$. Separiamo ora i casi di movimento della testina a destra e a sinistra.
	\begin{itemize}
		\item se la testina si muove a destra in uno stato $s$ (fig. \ref{fig:a1l:mright}), ci troviamo in corrispondenza della prima visita della cella successiva, perciò $A$ può spostarsi direttamente in un nuovo stato. La prima componente del nuovo stato sarà ovviamente $s$, mentre la tabella va aggiornata in modo da contenere l'informazione sulla cella appena lasciata, che è stata anche riscritta. La tabella per il nuovo stato sarà dunque $t_X(\tau)$, che rappresenta le possibili computazioni da $X$, qualora $M$ vi tornasse, che terminano quando la testina si muove alla sua destra nella nuova cella. Estendendo al caso nondeterministico, il movimento a destra può variare nello stato $s$ e nel simbolo scritto $X$, sono quindi necessarie le corrispondenti transizioni in ogni stato $[s,t_X(\tau)]$;
		\item se la testina si muove verso sinistra in uno stato $s$ (fig. \ref{fig:a1l:mleft}), occorre "aspettare" che $M$ effettui una computazione che termini a destra di $X$, nella prima visita di una nuova cella. La tabella dello stato risultante, come nel caso precedente, sarà $t_X(\tau)$, poiché la computazione a sinistra della nuova cella non può essere influenzata da ulteriori scritture. Lo stato risultante $q$ ci viene invece dato da $(s,q)\in m_X(\tau)$, che descrive il comportamento di $M$ all'arrivo nella nuova cella a partire dallo stato $s$ e dal simbolo a sinistra di $X$. Considerando anche il nondeterminismo, per ogni stato $s$ e simbolo $X$ vanno quindi costruite transizioni in $[q,t_X(\tau)]$, per ogni stato $q$ tale che $(s,q)\in m_X(\tau)$.
	\end{itemize}

	\begin{figure}
		\centering
		\subfloat[][$M$ muove la testina a destra. $A$ passa nello stato ${[s,t_X(\tau)]}$.\label{fig:a1l:mright}]{
			\hspace{.7cm}\input{img/mright.tikz}\hspace{.7cm}}
		\qquad
		\subfloat[][$M$ muove la testina a sinistra. $A$ passa nello stato ${[q,t_X(\tau)]}$.\label{fig:a1l:mleft}]{
			\hspace{.3cm}\input{img/mleft.tikz}\hspace{.3cm}}
		\caption{I due tipi di computazione di $M$ che corrispondono a una transizione in $A$.}
	\end{figure}

	Lo stato iniziale è la coppia $[q_0,\tau_\lem]$. Poiché un 1NFA non può leggere il simbolo $\rem$, è necessario un altro meccanismo per rendere uno stato finale. Uno stato $[s,\tau]$ è finale se e solo se $M$, giunto su $\rem$ nello stato $s$, possiede una computazione (in sola lettura e su tutto il nastro) che termina in uno stato finale $f\in F$ superato l'end-marker, cioè se $(s,f)\in t_\rem(\tau)$.

	Formalmente, $A:=\tuple{Q',\Sigma,\delta',q_0',F'}$ con
	\begin{itemize}
		\item $Q':=Q\times\subsets{Q\times Q}$;
		\item $q_0':=[q_0,\tau_\lem]$;
		\item $F':=\set{[p,\tau]\mid \exists q\in F: (p,q)\in t_\rem(\tau)}$
		\item dati $r,s\in Q,a\in\Sigma,X\in\Gamma_1,\tau\in\subsets{Q\times Q}$ le seguenti transizioni:
		      \begin{itemize}
			      \item per ogni $(s,X,\Right)\in\delta(r,a)$, $\delta'([r,\tau],a)$ contiene $[s,t_X(\tau)]$;
			      \item per ogni $(s,X,\Left)\in\delta(r,a)$, $\delta'([r,\tau],a)$ contiene $[q,t_X(\tau)]$ per ogni $q\in Q$ tale che $(s,q)\in m_X(\tau)$.
		      \end{itemize}
	\end{itemize}
	L'1NFA risultante ha $n\times 2^{n^2}$ stati. Benché $t_X$ e $m_X$ restituiscano diverse tabelle al variare di $X$, il numero di tabelle possibili, e quindi di stati di $A$, non dipende da $\card{\Gamma}$.

	\ref{itm:a1l:up:DFA} Usando la subset construction (\cite{Rabin:59:NFA}), $A$ può essere convertito in un 1DFA con $2^{2^{n^2}}$ stati.

	\ref{itm:a1l:up:det} Se $M$ è deterministico, ogni tabella di transizione è una funzione parziale $Q\to Q$, perciò $A$ ha al più $n\cdot(n+1)^n$ stati ($n+1$ immagini poiché si include la possibilità di non uscire dal segmento di nastro). Inoltre, per ogni tabella $\tau$, ogni stato $[r,\tau]$ possiede esattamente una transizione derivante da una transizione di $M$ per ciascun simbolo di input. $A$ è quindi un 1DFA.
\end{proof}


\subsection{Lower bound}\label{subs:a1l:low}
Studieremo ora i lower bound di conversione, facendo uso di \eng{witness languages} per dimostrare che esistono casi in cui i costi per le conversioni ottenute negli upper bound non possono essere significativamente migliorati. Per fare ciò, si cerca una famiglia di linguaggi per il cui riconoscimento esiste un \la1 con certo numero di stati $n$ e, al contempo, per cui un 1DFA necessita di un numero doppiamente esponenziale in $n$ di stati e un 1NFA, oppure 2NFA, 2DFA o D\la1 un numero esponenziale.\footnote{Non è necessario, in generale, che sia la stessa famiglia di linguaggi a dimostrare l'ottimalità delle diverse conversioni; tuttavia presenteremo un caso in cui ciò si verifica.}
\begin{theor}
	Per ogni $n>0$ intero, esiste un \la1 di $n$ stati tale che un 1DFA equivalente richiede un numero di stati doppiamente esponenziale in $n$.
\end{theor}

Si consideri il linguaggio $L_n$, dove $n\geq1$ è un parametro intero, delle parole binarie a blocchi di $n$ simboli in cui $n$ blocchi sono uguali:
\begin{align*}
	L_n := \{ & x_1x_2\cdots x_k\mid k\geq0, x_1,x_2,\dots,x_k\in\{0,1\}^n,                                   \\
	          & \exists i_1,i_2,\dots,i_n\in\{1,\dots,k\},i_1<i_2<\dots<i_n, x_{i_1}=x_{i_2}=\dots=x_{i_n}\}
\end{align*}

\begin{theor}
	$L_n$ può essere riconosciuto da un \la1 con un numero di stati in $O(n)$ e un alfabeto di lavoro indipendente da $n$.
\end{theor}
\begin{proof}
	Un \la1 $A_n$ può riconoscere $L_n$ come segue:
	\begin{enumerate}
		\SetKwData{B}{b}\SetKwData{C}{c}
	\item $A_n$ effettua una scansione preliminare dell'input, da sinistra verso destra, che verifichi tramite un contatore modulo $n$ inizializzato a $0$ che la parola sia effettivamente composta da blocchi di $n$ simboli, ossia che la sua lunghezza sia multipla di $n$. Se si raggiunge il right end-marker con il contatore non a zero, la macchina si ferma rifiutando. Durante questa scansione, l'unica in cui $A_n$ può scrivere, la macchina sceglie inoltre in modo nondeterministico le celle che danno inizio ai blocchi uguali. Ciò viene fatto in corrispondenza dell'azzeramento del contatore (in modo che i simboli siano all'inizio di blocchi) sostituendo i simboli con una loro versione segnata, che però mantenga l'informazione originale (per esempio $0$ in $\hat 0$).\footnote{Per semplicità diremo, con un abuso di notazione, che le altre celle non vengono modificate, tuttavia per correttezza formale queste vengono sempre sovrascritte con un simbolo in $\Gamma_1$ che rappresenta l'originale in $\Sigma$.} Questa fase richiede $O(n)$ stati per il contatore;
		\item viene poi effettuata una scansione verso sinistra fino a $\lem$, che verifichi che il numero di celle segnate, e quindi di blocchi candidati, sia $n$. Anche questa scansione richiede $O(n)$ stati;
		\item \label{itm:a1l:lowLn:LA3} la macchina prosegue poi verificando in sola lettura l'uguaglianza dei blocchi candidati, confrontando coppie di blocchi simbolo a simbolo. Per fare ciò la macchina implementa l'algoritmo \ref{alg:a1l:lowLn:3f}, una versione rivista e corretta dell'algoritmo presentato in \cite{Pighizzini:14:limitedRE}, che presentava qualche errore. Si ipotizzi di prendere in considerazione una coppia di blocchi candidati successivi. L'algoritmo fa uso di due variabili: la variabile intera \C, il cui dominio è $\set{0,\dots,n-1}$, rappresenta l'indice del simbolo che dev'essere confrontato nei due blocchi; la variabile \B contiene una copia del simbolo all'indice \C del primo blocco per confrontarla con il corrispondente simbolo nel secondo. Inizialmente $A_n$ scansiona il nastro da $\lem$ verso destra alla ricerca del primo simbolo segnato, e \C è inizializzata a $0$. A questo punto si entra nel ciclo principale, che confronta due blocchi successivi tra quelli segnati. La porzione di codice alle righe \refalgrange{algln:a1l:lowLn:3f}{1}{2} sposta la testina alla posizione di indice \C del primo blocco decrementando \C, salva una copia del simbolo nella variabile \B, quindi ripristina il valore di \C (modificando direttamente \C si risparmia l'utilizzo di un ulteriore indice variabile). La macchina prosegue poi individuando l'inizio del secondo blocco, accettando se trova invece $\rem$. Effettua quindi una procedura simile alla precedente per localizzare il simbolo in posizione \C (righe \refalgrange{algln:a1l:lowLn:3f}{3}{4}), questa volta però confrontandolo con quello contenuto in \B. Se i due sono diversi la macchina rifiuta, altrimenti prosegue. A questo punto, se $\C=n-1$ significa che i due blocchi sono stati confrontati, quindi si passa al confronto del secondo con il prossimo dei candidati. Per fare ciò è necessario unicamente resettare \C a $0$, dal momento che la testina è già nella corretta posizione. Se invece $\C<n-1$, si incrementa \C e si torna all'inizio del primo blocco per confrontare il prossimo simbolo. Questa fase richiede un numero di stati in $O(n)$ per memorizzare i valori di \B e \C.
	\end{enumerate}

	\IncMargin{1em}
	\begin{algorithm}
		\input{img/alg_Ln.tex}
		\caption{\hyperref[itm:a1l:lowLn:LA3]{Terza fase} del riconoscimento di $L_n$ da parte di $A_n$}
		\label{alg:a1l:lowLn:3f}
	\end{algorithm}
	\DecMargin{1em}
\end{proof}

Per dimostrare l'ottimalità dell'upper bound trovato in precedenza, dimostriamo che qualunque conversione non porterebbe alla costruzione di un 1DFA equivalente ad $A_n$ che abbia meno di un numero doppiamente esponenziale in $n$ di stati, poiché un tale 1DFA non può esistere. Il risultato viene poi esteso per l'ottimalità dei bound relativi a 1NFA, 2NFA, 2DFA e D\la1.
\begin{theor}\label{thm:a1l:lowLn}
	Sia $n\geq1$ un intero. Allora:
	\begin{enumerate}[(a)]
		\item \label{itm:a1l:lowLn:DFA} un 1DFA che riconosce $L_n$ necessita di un numero di stati doppiamente esponenziale in $n$;
		\item \label{itm:a1l:lowLn:1LA} un \la1 che riconosce $L_n$ necessita di un numero di stati polinomiale in $n$;
		\item \label{itm:a1l:lowLn:NFA} ogni D\la1, 2NFA, 2DFA o 1NFA che riconosce $L_n$ necessita di un numero di stati esponenziale in $n$.
	\end{enumerate}
\end{theor}
\begin{proof}
	\ref{itm:a1l:lowLn:DFA} Per dimostrare che un 1DFA che riconosce $L_n$ necessita di $2^{2^n}$ stati usiamo la tecnica delle stringhe distinguibili.

	Fissato un alfabeto, due stringhe $x$ e $y$ si dicono \emph{distinguibili} rispetto a un linguaggio $L$ se e solo se esiste una stringa $z$ tale che esattamente una tra le parole $xz$ e $yz$ appartiene a $L$. La cardinalità di un qualunque insieme di stringhe a due a due distinguibili è un lower bound per il numero di stati necessari a un 1DFA per riconoscere $L$.\footnote{Questa proprietà è una conseguenza del teorema di Myhill-Nerode.}

	Sia $x_1,x_2,\dots,x_{2^n}$, una lista in un ordine fissato di tutti i possibili blocchi, cioè stringhe in $\set{a,b}^n$. Sia $F:=\set{f: \set{1,\dots,2^n}\to\set{0,\dots,n-1}}$ l'insieme delle funzioni dagli indici dei blocchi agli interi tra $0$ e $n-1$. Scelto $f\in F$, sia $w_f$ la parola formata dalla giustapposizione dei blocchi $x_1,x_2,\dots,x_{2^n}$ in cui il blocco di indice $i$ è ripetuto $f(i)$ volte, ossia $w_f:=x_1^{f(1)}x_2^{f(2)}\cdots x_{2^n}^{f(2^n)}$. Si considerino ora due funzioni $f,g\in F$ tali che per un certo indice $j$, $f(j)\neq g(j)$. Le stringhe $w_f$ e $w_g$ sono distinguibili dalla stringa $z=x_j^{n-\max(f(j),g(j))}$, poiché una e una sola delle due parole $w_fz$ e $w_gz$ contiene $n$ ripetizioni del blocco $x_j$. Per esempio, se $f(j)>g(j)$:
	\begin{equation*}
		w_fz=x_1\cdots \underbrace{x_j\cdots x_j}_{f(j)} \cdots x_{2^n}\underbrace{x_j\cdots x_j}_{n-f(j)}\in L_n \qquad w_gz=x_1\cdots \underbrace{x_j\cdots x_j}_{g(j)} \cdots x_{2^n}\underbrace{x_j\cdots x_j}_{n-f(j)}\notin L_n
	\end{equation*}
	Dove il totale di ripetizioni del blocco $x_j$ in $w_fz$ sono $n$, mentre in $w_gz$ sono $g(j)+n-f(j)<n$.

	Ne si deduce, quindi, che la cardinalità dell'insieme delle parole $w_f$, con $f\in F$, è lower bound per il numero di stati di una 1DFA che riconosca $L_n$. Tale numero coincide con il numero di possibili funzioni $f$, ossia con $|F|=n^{2^n}\in\Omega(2^{2^n})$.

	\ref{itm:a1l:lowLn:1LA} Se il numero di stati di un \la1 che riconosca $L_n$ fosse meno che polinomiale in $n$, allora in virtù del teorema \ref{thm:a1l:upper} si potrebbe costruire un 1DFA meno che doppiamente esponenziale in $n$, il che contraddirebbe \ref{itm:a1l:lowLn:DFA}.

	\ref{itm:a1l:lowLn:NFA} Con un ragionamento analogo, considerando le costruzioni che permettono ai 1DFA di simulare 1NFA, 2NFA, 2DFA e D\la1, i cui risultati hanno dimensione esponenziale rispetto alle macchine simulate, dimostriamo che è impossibile che una di queste macchine che riconosca $L_n$ abbia un numero di stati meno che esponenziale in $n$.
\end{proof}
\noindent La dimostrazione di Pighizzini e Pisoni (\cite{Pighizzini:14:limitedRE}) estende il lower bound per i 1DFA a $((2^n-2)\cdot(\frac{n-1}{n})^2+1)\cdot n^{2^n}+1$ (tramite distinguibilità) e quello dei 1NFA a $n^2\cdot2^n$ (tramite \eng{fooling set}).

Il teorema \ref{thm:a1l:lowLn}, oltre a dimostrare che le conversioni da \la1 non possono essere migliorate significativamente, fornisce un lower bound esponenziale per la conversione da \la1 a D\la1:
\begin{corol}\label{cor:a1l:LAtoDLA}
	La simulazione di \la1 nondeterministici da parte di \la1 deterministici richiede un aumento esponenziale nel numero di stati.
\end{corol}
\begin{proof}
	L'esistenza di un \la1 deterministico meno che esponenziale in $n$ che riconosca $L_n$ permetterebbe la costruzione di un 1DFA equivalente meno che doppiamente esponenziale in $n$, con la simulazione presentata nel teorema \ref{thm:a1l:upper}. Questo, considerando i risultati illustrati nel teorema \ref{thm:a1l:lowLn}, è assurdo.
\end{proof}
